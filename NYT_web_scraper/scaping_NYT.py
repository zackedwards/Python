# importing libraries
import urllib2
from bs4 import BeautifulSoup

# setting the url
base_url = 'http://www.nytimes.com'

# querying the website and return the html to the variable 'page'
page = urllib2.urlopen(base_url)

# making the soup
soup = BeautifulSoup(page, 'lxml')

# initializing the list of words
words = []

# looping on the tree generated by BeautifulSoup
for story_heading in soup.find_all(class_ = 'story-heading'):
    story_title = story_heading.text.replace('\n', ' ').strip()
    new_story_title = story_title.encode('utf-8')
    story_title_list = new_story_title.split()
    print '\n',new_story_title
    for word in story_title_list:
        if word.isalpha():
            words.append(word)

# printing the words
print '\nwords', words
